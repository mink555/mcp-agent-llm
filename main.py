import os
import json
import time
import argparse
import pandas as pd
from datetime import datetime
from dotenv import load_dotenv
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
from openpyxl.utils import get_column_letter

from core.loader import BFCLDataLoader
from core.handler import ModelHandler
from core.checker import BFCLChecker
from core.executor import BFCLMockExecutor

def _format_model_name_for_filename(model_name):
    """
    ëª¨ë¸ëª…ì„ íŒŒì¼ëª…ì— ì í•©í•œ ì•½ì‹ìœ¼ë¡œ ë³€í™˜
    
    ì˜ˆì‹œ:
    - mistralai/mistral-small-3.2-24b-instruct â†’ mistral_small_3_2_24b
    - openai/gpt-4o-mini â†’ gpt_4o_mini
    - anthropic/claude-3-haiku â†’ claude_3_haiku
    """
    # íšŒì‚¬ëª…/ëª¨ë¸ëª… í˜•ì‹ì—ì„œ ëª¨ë¸ëª…ë§Œ ì¶”ì¶œ
    if '/' in model_name:
        model_name = model_name.split('/')[-1]
    
    # í•˜ì´í”ˆì„ ì–¸ë”ë°”ë¡œ ë³€í™˜
    model_name = model_name.replace('-', '_')
    
    # ì ì„ ì–¸ë”ë°”ë¡œ ë³€í™˜
    model_name = model_name.replace('.', '_')
    
    # ë¶ˆí•„ìš”í•œ ì ‘ë¯¸ì‚¬ ì œê±°
    suffixes_to_remove = ['_instruct', '_free', '_turbo', '_preview']
    for suffix in suffixes_to_remove:
        if model_name.endswith(suffix):
            model_name = model_name[:-len(suffix)]
    
    # ì†Œë¬¸ì ë³€í™˜
    model_name = model_name.lower()
    
    # ì—°ì†ëœ ì–¸ë”ë°” ì œê±°
    while '__' in model_name:
        model_name = model_name.replace('__', '_')
    
    # ì•ë’¤ ì–¸ë”ë°” ì œê±°
    model_name = model_name.strip('_')
    
    return model_name

# ==========================================
# [BFCL ê³µì‹ ì¹´í…Œê³ ë¦¬ ì •ì˜]
# ==========================================
# BFCL V3/V4 ì „ì²´ ì¹´í…Œê³ ë¦¬ (ê³µì‹ ë²¤ì¹˜ë§ˆí¬ êµ¬ì„± - ì´ 20ê°œ)
BFCL_ALL_CATEGORIES = {
    # Single-turn Non-Live (AST Evaluation)
    "simple_python": {"count": 399, "group": "AST_NON_LIVE", "difficulty": "â­"},
    "simple_javascript": {"count": 49, "group": "AST_NON_LIVE", "difficulty": "â­"},
    "simple_java": {"count": 99, "group": "AST_NON_LIVE", "difficulty": "â­"},
    "multiple": {"count": 199, "group": "AST_NON_LIVE", "difficulty": "â­â­"},
    "parallel": {"count": 199, "group": "AST_NON_LIVE", "difficulty": "â­â­"},
    "parallel_multiple": {"count": 199, "group": "AST_NON_LIVE", "difficulty": "â­â­â­"},
    
    # Single-turn Live (Executable + AST)
    "live_simple": {"count": 257, "group": "AST_LIVE", "difficulty": "â­â­"},
    "live_multiple": {"count": 1052, "group": "AST_LIVE", "difficulty": "â­â­"},
    "live_parallel": {"count": 15, "group": "AST_LIVE", "difficulty": "â­â­â­"},
    "live_parallel_multiple": {"count": 23, "group": "AST_LIVE", "difficulty": "â­â­â­"},
    
    # Multi-turn (State-based + Response-based)
    "multi_turn_base": {"count": 200, "group": "MULTI_TURN", "difficulty": "â­â­â­"},
    "multi_turn_miss_func": {"count": 200, "group": "MULTI_TURN", "difficulty": "â­â­â­"},
    "multi_turn_miss_param": {"count": 200, "group": "MULTI_TURN", "difficulty": "â­â­â­"},
    "multi_turn_long_context": {"count": 200, "group": "MULTI_TURN", "difficulty": "â­â­â­â­"},
    
    # Relevance Detection
    "irrelevance": {"count": 239, "group": "RELEVANCE", "difficulty": "â­â­"},
    "live_irrelevance": {"count": 884, "group": "RELEVANCE", "difficulty": "â­â­"},
    "live_relevance": {"count": 16, "group": "RELEVANCE", "difficulty": "â­â­"},
    
    # Agentic (V4 ì¶”ê°€)
    "web_search": {"count": 99, "group": "AGENTIC", "difficulty": "â­â­â­"},
    "memory": {"count": 155, "group": "AGENTIC", "difficulty": "â­â­â­"},
    "format_sensitivity": {"count": 9, "group": "AGENTIC", "difficulty": "â­â­"},
}

# ==========================================
# [ê¸°ë³¸ ì„¤ì •]
# ==========================================
DEFAULT_CONFIG = {
    "model_name": "mistralai/mistral-small-3.2-24b-instruct",  # ìœ ë£Œ ëª¨ë¸ (tool calling ì§€ì›)
    "categories": list(BFCL_ALL_CATEGORIES.keys()),  # ì „ì²´ ì¹´í…Œê³ ë¦¬
    "samples_per_cat": 5,  # ê° ì¹´í…Œê³ ë¦¬ë‹¹ ê¸°ë³¸ ìƒ˜í”Œ ìˆ˜
    "sampling_strategy": "equal",  # "equal" or "proportional"
    "max_agent_steps": 3,
    "rate_limit_delay": 3  # API ë ˆì´íŠ¸ ë¦¬ë°‹ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
}

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì„¤ì •
QUICK_TEST_CONFIG = {
    "samples_per_cat": 2,
    "categories": ["simple_python", "multiple", "live_simple"],  # 3ê°œ ëŒ€í‘œ ì¹´í…Œê³ ë¦¬
    "sampling_strategy": "equal",
    "rate_limit_delay": 5
}

# ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì„¤ì • (ëª¨ë“  ë°ì´í„° ì‚¬ìš©)
FULL_TEST_CONFIG = {
    "samples_per_cat": 999999,  # ê° ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  ìƒ˜í”Œ ì‚¬ìš©
    "categories": list(BFCL_ALL_CATEGORIES.keys()),  # ì „ì²´ 20ê°œ ì¹´í…Œê³ ë¦¬
    "sampling_strategy": "equal",
    "rate_limit_delay": 3
}

class BFCLScorer:
    """BFCL í‘œì¤€ ì ìˆ˜ ì‚°ì¶œ í´ë˜ìŠ¤"""
    
    @staticmethod
    def calculate_scores(df):
        """BFCL ê³µì‹ ì ìˆ˜ ì‚°ì¶œ ë°©ë²•ì— ë”°ë¼ í†µê³„ ê³„ì‚°"""
        scores = {}
        
        # 1. ì¹´í…Œê³ ë¦¬ë³„ ì •í™•ë„
        for cat in df['ì¹´í…Œê³ ë¦¬'].unique():
            cat_df = df[df['ì¹´í…Œê³ ë¦¬'] == cat]
            pass_count = len(cat_df[cat_df['ê²°ê³¼'] == 'PASS'])
            total_count = len(cat_df)
            accuracy = (pass_count / total_count * 100) if total_count > 0 else 0
            scores[cat] = {
                "accuracy": accuracy,
                "pass": pass_count,
                "total": total_count,
                "group": BFCL_ALL_CATEGORIES.get(cat, {}).get("group", "UNKNOWN")
            }
        
        # 2. ê·¸ë£¹ë³„ í‰ê·  ì •í™•ë„
        groups = {}
        for cat, data in scores.items():
            group = data["group"]
            if group not in groups:
                groups[group] = []
            groups[group].append(data["accuracy"])
        
        group_scores = {group: sum(accs) / len(accs) if accs else 0 
                       for group, accs in groups.items()}
        
        # 3. Overall ì •í™•ë„ (unweighted average of all categories)
        all_accuracies = [data["accuracy"] for data in scores.values()]
        overall_accuracy = sum(all_accuracies) / len(all_accuracies) if all_accuracies else 0
        
        return {
            "overall": overall_accuracy,
            "by_category": scores,
            "by_group": group_scores
        }

class ExcelReporter:
    """BFCL í‘œì¤€ ë©€í‹° ì‹œíŠ¸ Excel ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""
    
    @staticmethod
    def save(df, path, model_name, config):
        """BFCL í‘œì¤€ 4-ì‹œíŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        with pd.ExcelWriter(path, engine='openpyxl') as writer:
            # 1. ìƒì„¸ ê²°ê³¼ ì‹œíŠ¸
            ExcelReporter._write_result_sheet(writer, df)
            
            # 2. ìš”ì•½ í†µê³„ ì‹œíŠ¸ (BFCL ìŠ¤íƒ€ì¼)
            ExcelReporter._write_summary_sheet(writer, df, model_name)
            
            # 3. ë°ì´í„°ì…‹ ì •ë³´ ì‹œíŠ¸
            ExcelReporter._write_dataset_info_sheet(writer)
            
            # 4. ì°¸ê³  ìë£Œ ì‹œíŠ¸
            ExcelReporter._write_reference_sheet(writer)
    
    @staticmethod
    def _write_result_sheet(writer, df):
        """ìƒì„¸ ê²°ê³¼ ì‹œíŠ¸ (ê¸°ì¡´ ìŠ¤íƒ€ì¼ ìœ ì§€)"""
        # NaNì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜ (Excel ì˜¤ë¥˜ ë°©ì§€)
        df = df.fillna("")
        df.to_excel(writer, index=False, sheet_name='Detailed Results')
        ws = writer.sheets['Detailed Results']
        
        # ìŠ¤íƒ€ì¼ ì •ì˜
        header_fill = PatternFill(start_color='F2F2F2', end_color='F2F2F2', fill_type='solid')
        stripe_fill = PatternFill(start_color='FAFAFA', end_color='FAFAFA', fill_type='solid')
        pass_font = Font(color='2E7D32', bold=True)
        fail_font = Font(color='D32F2F', bold=True)
        border = Border(
            left=Side(style='thin', color='E0E0E0'), 
            right=Side(style='thin', color='E0E0E0'), 
            top=Side(style='thin', color='E0E0E0'), 
            bottom=Side(style='thin', color='E0E0E0')
        )

        # í—¤ë” ìŠ¤íƒ€ì¼ë§
        for col_idx in range(1, len(df.columns) + 1):
            cell = ws.cell(row=1, column=col_idx)
            cell.fill = header_fill
            cell.font = Font(bold=True)
            cell.alignment = Alignment(horizontal='center', vertical='center')
            cell.border = border

        # ë³¸ë¬¸ ìŠ¤íƒ€ì¼ë§
        for row_idx in range(2, len(df) + 2):
            is_stripe = row_idx % 2 == 0
            for col_idx in range(1, len(df.columns) + 1):
                cell = ws.cell(row=row_idx, column=col_idx)
                if is_stripe: cell.fill = stripe_fill
                cell.border = border
                cell.alignment = Alignment(vertical='top', wrap_text=True, indent=1)
                
                if col_idx == 3: # ê²°ê³¼ ì»¬ëŸ¼ (PASS/FAIL)
                    cell.font = pass_font if cell.value == "PASS" else fail_font
                    cell.alignment = Alignment(horizontal='center', vertical='center')

        # ë„ˆë¹„ ì„¤ì •
        col_widths = [15, 15, 10, 40, 30, 30, 30, 30, 15]
        for i, width in enumerate(col_widths):
            ws.column_dimensions[get_column_letter(i+1)].width = width
        ws.freeze_panes = 'C2'
    
    @staticmethod
    def _write_summary_sheet(writer, df, model_name):
        """BFCL ìŠ¤íƒ€ì¼ ìš”ì•½ í†µê³„ ì‹œíŠ¸ (í•œêµ­ì–´ í¬í•¨, Excel ìˆ˜ì‹ ìë™ ì§‘ê³„)"""
        scores = BFCLScorer.calculate_scores(df)
        
        # ì¹´í…Œê³ ë¦¬ë³„ í–‰ ë²ˆí˜¸ ë§¤í•‘ (Detailed Results ì‹œíŠ¸ ì°¸ì¡°ìš©)
        category_rows = {}
        for idx, cat in enumerate(df['ì¹´í…Œê³ ë¦¬'].unique()):
            # Excelì€ 1-based, í—¤ë”ê°€ 1í–‰ì´ë¯€ë¡œ ë°ì´í„°ëŠ” 2í–‰ë¶€í„°
            cat_df = df[df['ì¹´í…Œê³ ë¦¬'] == cat]
            first_row = df[df['ì¹´í…Œê³ ë¦¬'] == cat].index[0] + 2  # +2 for Excel indexing
            last_row = first_row + len(cat_df) - 1
            category_rows[cat] = (first_row, last_row)
        
        # ìš”ì•½ ë°ì´í„° êµ¬ì„±
        summary_data = []
        
        # ëª¨ë¸ ì •ë³´
        summary_data.append({
            "ì§€í‘œ (Metric)": "í…ŒìŠ¤íŠ¸ ëª¨ë¸ (Model)",
            "ê°’ (Value)": model_name,
            "ì„¤ëª… (Description)": "í‰ê°€ì— ì‚¬ìš©ëœ LLM ëª¨ë¸"
        })
        summary_data.append({
            "ì§€í‘œ (Metric)": " ",
            "ê°’ (Value)": " ",
            "ì„¤ëª… (Description)": " "
        })
        
        # Overall Score (ìˆ˜ì‹ìœ¼ë¡œ ê³„ì‚°)
        summary_data.append({
            "ì§€í‘œ (Metric)": "ì „ì²´ ì •í™•ë„ (Overall Accuracy)",
            "ê°’ (Value)": "FORMULA_OVERALL_ACC",  # ë‚˜ì¤‘ì— ìˆ˜ì‹ìœ¼ë¡œ êµì²´
            "ì„¤ëª… (Description)": "ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ ë¹„ê°€ì¤‘ í‰ê·  (BFCL í‘œì¤€)"
        })
        summary_data.append({
            "ì§€í‘œ (Metric)": "ğŸ“Š ì ìˆ˜ ì‚°ì¶œ ê³µì‹",
            "ê°’ (Value)": "Î£(Category Acc) / N",
            "ì„¤ëª… (Description)": "N = ì¹´í…Œê³ ë¦¬ ìˆ˜, ê° ì¹´í…Œê³ ë¦¬ì— ë™ì¼í•œ ê°€ì¤‘ì¹˜ ë¶€ì—¬"
        })
        summary_data.append({
            "ì§€í‘œ (Metric)": " ",
            "ê°’ (Value)": " ",
            "ì„¤ëª… (Description)": " "
        })
        
        # ê·¸ë£¹ë³„ ì ìˆ˜ (ìˆ˜ì‹ìœ¼ë¡œ ê³„ì‚°)
        summary_data.append({
            "ì§€í‘œ (Metric)": "â”â”â” ê·¸ë£¹ë³„ ì ìˆ˜ (Group Scores) â”â”â”",
            "ê°’ (Value)": " ",
            "ì„¤ëª… (Description)": " "
        })
        
        group_row_start = len(summary_data) + 2  # í˜„ì¬ê¹Œì§€ì˜ í–‰ ìˆ˜ + í—¤ë”
        
        for group in sorted(set(scores['by_group'].keys())):
            group_kr = {
                "AST_NON_LIVE": "AST ë¹„ì‹¤í–‰ í‰ê°€",
                "AST_LIVE": "AST ì‹¤í–‰ í‰ê°€",
                "MULTI_TURN": "ë©€í‹°í„´ ëŒ€í™”",
                "RELEVANCE": "ê´€ë ¨ì„± íƒì§€",
                "AGENTIC": "ì—ì´ì „íŠ¸ ê¸°ëŠ¥"
            }.get(group, group)
            summary_data.append({
                "ì§€í‘œ (Metric)": f"{group} ({group_kr})",
                "ê°’ (Value)": f"FORMULA_GROUP_{group}",  # ë‚˜ì¤‘ì— ìˆ˜ì‹ìœ¼ë¡œ êµì²´
                "ì„¤ëª… (Description)": f"{group} ê·¸ë£¹ ë‚´ ì¹´í…Œê³ ë¦¬ë“¤ì˜ í‰ê·  ì •í™•ë„"
            })
        
        summary_data.append({
            "ì§€í‘œ (Metric)": " ",
            "ê°’ (Value)": " ",
            "ì„¤ëª… (Description)": " "
        })
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ì ìˆ˜ (ìˆ˜ì‹ìœ¼ë¡œ ê³„ì‚°)
        cat_row_start = len(summary_data) + 2
        
        summary_data.append({
            "ì§€í‘œ (Metric)": "â”â”â” ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ (Category Scores) â”â”â”",
            "ê°’ (Value)": " ",
            "ì„¤ëª… (Description)": " "
        })
        
        for cat, data in scores['by_category'].items():
            cat_kr = ExcelReporter._get_category_name_korean(cat)
            summary_data.append({
                "ì§€í‘œ (Metric)": f"{cat} ({cat_kr})",
                "ê°’ (Value)": f"FORMULA_CAT_{cat}",  # ë‚˜ì¤‘ì— ìˆ˜ì‹ìœ¼ë¡œ êµì²´
                "ì„¤ëª… (Description)": f"ê·¸ë£¹: {data['group']}, ìˆ˜ì‹ ìë™ ê³„ì‚°"
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_df = summary_df.fillna("")
        summary_df.to_excel(writer, index=False, sheet_name='Summary (BFCL)')
        
        # ìŠ¤íƒ€ì¼ë§ ë° ìˆ˜ì‹ ì‚½ì…
        ws = writer.sheets['Summary (BFCL)']
        ws.column_dimensions['A'].width = 35
        ws.column_dimensions['B'].width = 22
        ws.column_dimensions['C'].width = 55
        
        # ìŠ¤íƒ€ì¼ ì •ì˜
        header_fill = PatternFill(start_color='F2F2F2', end_color='F2F2F2', fill_type='solid')
        stripe_fill = PatternFill(start_color='FAFAFA', end_color='FAFAFA', fill_type='solid')
        section_fill = PatternFill(start_color='E7E6E6', end_color='E7E6E6', fill_type='solid')
        border = Border(
            left=Side(style='thin', color='E0E0E0'),
            right=Side(style='thin', color='E0E0E0'),
            top=Side(style='thin', color='E0E0E0'),
            bottom=Side(style='thin', color='E0E0E0')
        )
        
        # í—¤ë” ìŠ¤íƒ€ì¼ë§
        for col_idx in range(1, 4):
            cell = ws.cell(row=1, column=col_idx)
            cell.fill = header_fill
            cell.font = Font(bold=True)
            cell.alignment = Alignment(horizontal='center', vertical='center')
            cell.border = border
        
        # ìˆ˜ì‹ ì‚½ì… ë° ë³¸ë¬¸ ìŠ¤íƒ€ì¼ë§
        for row_idx in range(2, len(summary_df) + 2):
            cell_a = ws.cell(row=row_idx, column=1)
            cell_b = ws.cell(row=row_idx, column=2)
            cell_c = ws.cell(row=row_idx, column=3)
            
            # Excel ìˆ˜ì‹ ì‚½ì…
            if cell_b.value and isinstance(cell_b.value, str):
                # Overall Accuracy ìˆ˜ì‹
                if cell_b.value == "FORMULA_OVERALL_ACC":
                    # ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ë“¤ì˜ í‰ê·  (í¼ì„¼íŠ¸ ê°’ ì¶”ì¶œ, ì†Œìˆ˜ì  ì²«ì§¸ìë¦¬ê¹Œì§€)
                    cat_start_row = cat_row_start + 1  # ì„¹ì…˜ í—¤ë” ë‹¤ìŒ í–‰ë¶€í„°
                    cat_end_row = cat_start_row + len(scores['by_category']) - 1
                    # ê° ì¹´í…Œê³ ë¦¬ì˜ í¼ì„¼íŠ¸ ê°’ ì¶”ì¶œí•˜ì—¬ í‰ê· 
                    value_extracts = [f'VALUE(LEFT(B{r},FIND("%",B{r})-1))' for r in range(cat_start_row, cat_end_row + 1)]
                    cell_b.value = f'=ROUND(AVERAGE({",".join(value_extracts)}),1)&"%"'
                
                # ê·¸ë£¹ë³„ ìˆ˜ì‹
                elif cell_b.value.startswith("FORMULA_GROUP_"):
                    group = cell_b.value.replace("FORMULA_GROUP_", "")
                    # í•´ë‹¹ ê·¸ë£¹ì— ì†í•˜ëŠ” ì¹´í…Œê³ ë¦¬ë“¤ì˜ í–‰ ë²ˆí˜¸ ì°¾ê¸°
                    group_cats = [cat for cat, data in scores['by_category'].items() if data['group'] == group]
                    if group_cats:
                        cat_rows = []
                        for i, cat in enumerate(scores['by_category'].keys()):
                            if cat in group_cats:
                                cat_rows.append(cat_row_start + 1 + i)
                        
                        if len(cat_rows) == 1:
                            # í¼ì„¼íŠ¸ ê°’ ì¶”ì¶œ: LEFT(B12, FIND("%", B12)-1)
                            cell_b.value = f'=VALUE(LEFT(B{cat_rows[0]},FIND("%",B{cat_rows[0]})-1))&"%"'
                        else:
                            # ê° ì¹´í…Œê³ ë¦¬ì˜ í¼ì„¼íŠ¸ ê°’ ì¶”ì¶œí•˜ì—¬ í‰ê·  (ì†Œìˆ˜ì  ì²«ì§¸ìë¦¬ê¹Œì§€)
                            value_extracts = [f'VALUE(LEFT(B{r},FIND("%",B{r})-1))' for r in cat_rows]
                            cell_b.value = f'=ROUND(AVERAGE({",".join(value_extracts)}),1)&"%"'
                
                # ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì‹
                elif cell_b.value.startswith("FORMULA_CAT_"):
                    cat = cell_b.value.replace("FORMULA_CAT_", "")
                    if cat in category_rows:
                        first_row, last_row = category_rows[cat]
                        # PASS ê°œìˆ˜ / ì „ì²´ ê°œìˆ˜ * 100 (ì†Œìˆ˜ì  ì²«ì§¸ìë¦¬ê¹Œì§€)
                        pass_formula = f'COUNTIF(\'Detailed Results\'!C{first_row}:C{last_row},"PASS")'
                        total_formula = f'COUNTA(\'Detailed Results\'!C{first_row}:C{last_row})'
                        cell_b.value = f'=IF({total_formula}=0,0,ROUND({pass_formula}/{total_formula}*100,1))&"%"&" ("&{pass_formula}&"/"&{total_formula}&")"'
            
            # ë¹ˆ í–‰ì€ ìŠ¤íƒ€ì¼ ì—†ìŒ
            if cell_a.value and str(cell_a.value).strip() == "":
                continue
            # ì„¹ì…˜ êµ¬ë¶„ì„  ê°•ì¡°
            elif cell_a.value and ("â”â”â”" in str(cell_a.value) or "===" in str(cell_a.value)):
                cell_a.fill = section_fill
                cell_a.font = Font(bold=True, color='333333')
                cell_b.fill = section_fill
                cell_c.fill = section_fill
            # ìŠ¤íŠ¸ë¼ì´í”„ íš¨ê³¼
            elif row_idx % 2 == 0:
                cell_a.fill = stripe_fill
                cell_b.fill = stripe_fill
                cell_c.fill = stripe_fill
            
            # í…Œë‘ë¦¬ ë° ì •ë ¬
            for cell in [cell_a, cell_b, cell_c]:
                cell.border = border
                cell.alignment = Alignment(vertical='center', wrap_text=True, indent=1)
            
            # Value ì»¬ëŸ¼ ì¤‘ì•™ ì •ë ¬
            cell_b.alignment = Alignment(horizontal='center', vertical='center')
            
            # Overall Accuracy ê°•ì¡°
            if "ì „ì²´ ì •í™•ë„" in str(cell_a.value):
                cell_a.font = Font(bold=True, size=11)
                cell_b.font = Font(bold=True, color='2E7D32', size=12)
                cell_b.alignment = Alignment(horizontal='center', vertical='center')
        
        ws.freeze_panes = 'A2'
    
    @staticmethod
    def _write_dataset_info_sheet(writer):
        """ë°ì´í„°ì…‹ ì •ë³´ ì‹œíŠ¸ (í•œêµ­ì–´ í¬í•¨)"""
        dataset_info = []
        
        for cat, info in BFCL_ALL_CATEGORIES.items():
            cat_kr = ExcelReporter._get_category_name_korean(cat)
            dataset_info.append({
                "ì¹´í…Œê³ ë¦¬ (Category)": f"{cat}\n({cat_kr})",
                "ì „ì²´ ê°œìˆ˜\n(Total Count)": info["count"],
                "ê·¸ë£¹\n(Group)": info["group"],
                "ë‚œì´ë„\n(Difficulty)": info["difficulty"],
                "ì„¤ëª… (Description)": ExcelReporter._get_category_description(cat)
            })
        
        info_df = pd.DataFrame(dataset_info)
        # NaNì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜ (Excel ì˜¤ë¥˜ ë°©ì§€)
        info_df = info_df.fillna("")
        info_df.to_excel(writer, index=False, sheet_name='Dataset Info')
        
        # ìŠ¤íƒ€ì¼ë§ (Detailed Results ìŠ¤íƒ€ì¼ ìœ ì§€)
        ws = writer.sheets['Dataset Info']
        ws.column_dimensions['A'].width = 30
        ws.column_dimensions['B'].width = 14
        ws.column_dimensions['C'].width = 20
        ws.column_dimensions['D'].width = 14
        ws.column_dimensions['E'].width = 60
        
        # ìŠ¤íƒ€ì¼ ì •ì˜
        header_fill = PatternFill(start_color='F2F2F2', end_color='F2F2F2', fill_type='solid')
        stripe_fill = PatternFill(start_color='FAFAFA', end_color='FAFAFA', fill_type='solid')
        border = Border(
            left=Side(style='thin', color='E0E0E0'),
            right=Side(style='thin', color='E0E0E0'),
            top=Side(style='thin', color='E0E0E0'),
            bottom=Side(style='thin', color='E0E0E0')
        )
        
        # í—¤ë” ìŠ¤íƒ€ì¼ë§
        for col_idx in range(1, 6):
            cell = ws.cell(row=1, column=col_idx)
            cell.fill = header_fill
            cell.font = Font(bold=True)
            cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
            cell.border = border
        
        # ë³¸ë¬¸ ìŠ¤íƒ€ì¼ë§
        for row_idx in range(2, len(info_df) + 2):
            is_stripe = row_idx % 2 == 0
            for col_idx in range(1, 6):
                cell = ws.cell(row=row_idx, column=col_idx)
                if is_stripe:
                    cell.fill = stripe_fill
                cell.border = border
                cell.alignment = Alignment(vertical='center', wrap_text=True, indent=1)
                
                # ì¤‘ì•™ ì •ë ¬ (Count, Difficulty)
                if col_idx in [2, 4]:
                    cell.alignment = Alignment(horizontal='center', vertical='center')
        
        ws.freeze_panes = 'A2'
    
    @staticmethod
    def _write_reference_sheet(writer):
        """ì°¸ê³  ìë£Œ ì‹œíŠ¸ (í•œêµ­ì–´ í¬í•¨)"""
        references = [
            {"êµ¬ë¶„ (Section)": "ğŸ“Š BFCL ê³µì‹ (Official)", "ë‚´ìš© (Content)": "Berkeley Function Calling Leaderboard (BFCL)"},
            {"êµ¬ë¶„ (Section)": "ğŸŒ ì›¹ì‚¬ì´íŠ¸ (Website)", "ë‚´ìš© (Content)": "https://gorilla.cs.berkeley.edu/leaderboard.html"},
            {"êµ¬ë¶„ (Section)": "ğŸ’» GitHub", "ë‚´ìš© (Content)": "https://github.com/ShishirPatil/gorilla/tree/main/berkeley-function-call-leaderboard"},
            {"êµ¬ë¶„ (Section)": "ğŸ“ Dataset", "ë‚´ìš© (Content)": "https://huggingface.co/datasets/gorilla-llm/Berkeley-Function-Calling-Leaderboard"},
            {"êµ¬ë¶„ (Section)": " ", "ë‚´ìš© (Content)": " "},
            {"êµ¬ë¶„ (Section)": "â”â”â” í‰ê°€ ë°©ë²• (Evaluation Methods) â”â”â”", "ë‚´ìš© (Content)": " "},
            {"êµ¬ë¶„ (Section)": "ğŸŒ³ AST í‰ê°€", "ë‚´ìš© (Content)": "ì¶”ìƒ êµ¬ë¬¸ íŠ¸ë¦¬ ë¹„êµ (Abstract Syntax Tree comparison for structural correctness)"},
            {"êµ¬ë¶„ (Section)": "âš™ï¸ ì‹¤í–‰ í‰ê°€", "ë‚´ìš© (Content)": "REST API ë° Python í•¨ìˆ˜ ì‹¤ì œ ì‹¤í–‰ (Actual execution for REST APIs and Python functions)"},
            {"êµ¬ë¶„ (Section)": "âœ… ê´€ë ¨ì„± íƒì§€", "ë‚´ìš© (Content)": "ê´€ë ¨ ì—†ëŠ” í•¨ìˆ˜ í˜¸ì¶œ íšŒí”¼ ëŠ¥ë ¥ (Ability to avoid irrelevant function calls)"},
            {"êµ¬ë¶„ (Section)": "ğŸ”€ ë³‘ë ¬ í˜¸ì¶œ ìˆœì„œ", "ë‚´ìš© (Content)": "BFCL í‘œì¤€: ë³‘ë ¬(parallel) ì¹´í…Œê³ ë¦¬ëŠ” í˜¸ì¶œ ìˆœì„œ ë¬´ì‹œ. ì§‘í•©ì²˜ëŸ¼ ë§¤ì¹­ (Order-independent matching for parallel function calls)"},
            {"êµ¬ë¶„ (Section)": " ", "ë‚´ìš© (Content)": " "},
            {"êµ¬ë¶„ (Section)": "â”â”â” ì ìˆ˜ ì‚°ì¶œ (Scoring) â”â”â”", "ë‚´ìš© (Content)": " "},
            {"êµ¬ë¶„ (Section)": "ğŸ“ˆ ì „ì²´ ì •í™•ë„", "ë‚´ìš© (Content)": "Overall Accuracy = Î£(Category Accuracy) / N (ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ ë¹„ê°€ì¤‘ í‰ê· )"},
            {"êµ¬ë¶„ (Section)": "ğŸ“Š ì¹´í…Œê³ ë¦¬ ì •í™•ë„", "ë‚´ìš© (Content)": "Category Accuracy = (PASS count / Total count) Ã— 100%"},
            {"êµ¬ë¶„ (Section)": "ğŸ“‚ ê·¸ë£¹ ì •í™•ë„", "ë‚´ìš© (Content)": "Group Accuracy = ë™ì¼ ê·¸ë£¹ ë‚´ ì¹´í…Œê³ ë¦¬ë“¤ì˜ í‰ê·  (Average of categories within same group)"},
            {"êµ¬ë¶„ (Section)": " ", "ë‚´ìš© (Content)": " "},
            {"êµ¬ë¶„ (Section)": "â”â”â” ë…¼ë¬¸ (Papers) â”â”â”", "ë‚´ìš© (Content)": " "},
            {"êµ¬ë¶„ (Section)": "ğŸ“„ BFCL v1", "ë‚´ìš© (Content)": "AST í‰ê°€ ë©”íŠ¸ë¦­ ë„ì… (Introducing AST evaluation metric)"},
            {"êµ¬ë¶„ (Section)": "ğŸ“„ BFCL v2", "ë‚´ìš© (Content)": "ê¸°ì—… ë° OSS ê¸°ì—¬ í•¨ìˆ˜ (Enterprise and OSS-contributed functions)"},
            {"êµ¬ë¶„ (Section)": "ğŸ“„ BFCL v3", "ë‚´ìš© (Content)": "ë©€í‹°í„´ ìƒí˜¸ì‘ìš© (Multi-turn interactions)"},
            {"êµ¬ë¶„ (Section)": "ğŸ“„ BFCL v4", "ë‚´ìš© (Content)": "ì¢…í•©ì  ì—ì´ì „íŠ¸ í‰ê°€ (Holistic agentic evaluation)"},
        ]
        
        ref_df = pd.DataFrame(references)
        # NaNì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜ (Excel ì˜¤ë¥˜ ë°©ì§€)
        ref_df = ref_df.fillna("")
        ref_df.to_excel(writer, index=False, sheet_name='Reference')
        
        # ìŠ¤íƒ€ì¼ë§ (Detailed Results ìŠ¤íƒ€ì¼ ìœ ì§€)
        ws = writer.sheets['Reference']
        ws.column_dimensions['A'].width = 32
        ws.column_dimensions['B'].width = 85
        
        # ìŠ¤íƒ€ì¼ ì •ì˜
        header_fill = PatternFill(start_color='F2F2F2', end_color='F2F2F2', fill_type='solid')
        stripe_fill = PatternFill(start_color='FAFAFA', end_color='FAFAFA', fill_type='solid')
        section_fill = PatternFill(start_color='E7E6E6', end_color='E7E6E6', fill_type='solid')
        border = Border(
            left=Side(style='thin', color='E0E0E0'),
            right=Side(style='thin', color='E0E0E0'),
            top=Side(style='thin', color='E0E0E0'),
            bottom=Side(style='thin', color='E0E0E0')
        )
        
        # í—¤ë” ìŠ¤íƒ€ì¼ë§
        for col_idx in range(1, 3):
            cell = ws.cell(row=1, column=col_idx)
            cell.fill = header_fill
            cell.font = Font(bold=True)
            cell.alignment = Alignment(horizontal='center', vertical='center')
            cell.border = border
        
        # ë³¸ë¬¸ ìŠ¤íƒ€ì¼ë§
        for row_idx in range(2, len(ref_df) + 2):
            cell_a = ws.cell(row=row_idx, column=1)
            cell_b = ws.cell(row=row_idx, column=2)
            
            # ë¹ˆ í–‰ì€ ìŠ¤íƒ€ì¼ ì—†ìŒ
            if cell_a.value and str(cell_a.value).strip() == "":
                continue
            # ì„¹ì…˜ êµ¬ë¶„ì„  ê°•ì¡°
            elif cell_a.value and "â”â”â”" in str(cell_a.value):
                cell_a.fill = section_fill
                cell_a.font = Font(bold=True, color='333333')
                cell_b.fill = section_fill
            # ìŠ¤íŠ¸ë¼ì´í”„ íš¨ê³¼
            elif row_idx % 2 == 0:
                cell_a.fill = stripe_fill
                cell_b.fill = stripe_fill
            
            # í…Œë‘ë¦¬ ë° ì •ë ¬
            for cell in [cell_a, cell_b]:
                cell.border = border
                cell.alignment = Alignment(vertical='center', wrap_text=True, indent=1)
        
        ws.freeze_panes = 'A2'
    
    @staticmethod
    def _get_category_name_korean(cat):
        """ì¹´í…Œê³ ë¦¬ í•œêµ­ì–´ ì´ë¦„ ë°˜í™˜"""
        korean_names = {
            "simple_python": "ë‹¨ì¼ Python",
            "simple_javascript": "ë‹¨ì¼ JavaScript",
            "simple_java": "ë‹¨ì¼ Java",
            "multiple": "ë‹¤ì¤‘ íŒŒë¼ë¯¸í„°",
            "parallel": "ë³‘ë ¬ í˜¸ì¶œ",
            "parallel_multiple": "ë³‘ë ¬ ë‹¤ì¤‘",
            "live_simple": "ì‹¤í–‰ ë‹¨ì¼",
            "live_multiple": "ì‹¤í–‰ ë‹¤ì¤‘",
            "live_parallel": "ì‹¤í–‰ ë³‘ë ¬",
            "live_parallel_multiple": "ì‹¤í–‰ ë³‘ë ¬ ë‹¤ì¤‘",
            "multi_turn_base": "ë©€í‹°í„´ ê¸°ë³¸",
            "multi_turn_miss_func": "ë©€í‹°í„´ í•¨ìˆ˜ëˆ„ë½",
            "multi_turn_miss_param": "ë©€í‹°í„´ íŒŒë¼ë¯¸í„°ëˆ„ë½",
            "multi_turn_long_context": "ë©€í‹°í„´ ê¸´ì»¨í…ìŠ¤íŠ¸",
            "irrelevance": "ê´€ë ¨ì—†ìŒ íƒì§€",
            "live_irrelevance": "ì‹¤í–‰ ê´€ë ¨ì—†ìŒ",
            "live_relevance": "ì‹¤í–‰ ê´€ë ¨ì„±",
            "web_search": "ì›¹ ê²€ìƒ‰",
            "memory": "ë©”ëª¨ë¦¬ ê´€ë¦¬",
            "format_sensitivity": "í¬ë§· ë¯¼ê°ë„",
        }
        return korean_names.get(cat, cat)
    
    @staticmethod
    def _get_category_description(cat):
        """ì¹´í…Œê³ ë¦¬ë³„ ì„¤ëª… ë°˜í™˜ (í•œêµ­ì–´ + ì˜ì–´)"""
        descriptions = {
            "simple_python": "ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ë‹¨ì¼ Python í•¨ìˆ˜ í˜¸ì¶œ | Single Python function call with basic parameters",
            "simple_javascript": "ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ë‹¨ì¼ JavaScript í•¨ìˆ˜ í˜¸ì¶œ | Single JavaScript function call with basic parameters",
            "simple_java": "ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ë‹¨ì¼ Java í•¨ìˆ˜ í˜¸ì¶œ | Single Java function call with basic parameters",
            "multiple": "ë‹¨ì¼ í•¨ìˆ˜ì— ì—¬ëŸ¬ íŒŒë¼ë¯¸í„° ì „ë‹¬ | Multiple parameters in single function call",
            "parallel": "ì—¬ëŸ¬ í•¨ìˆ˜ë¥¼ ë³‘ë ¬ë¡œ í˜¸ì¶œ (ìˆœì„œ ë¬´ì‹œ) | Multiple functions called in parallel (order-independent)",
            "parallel_multiple": "ì—¬ëŸ¬ í•¨ìˆ˜ë¥¼ ë‹¤ì¤‘ íŒŒë¼ë¯¸í„°ë¡œ ë³‘ë ¬ í˜¸ì¶œ (ìˆœì„œ ë¬´ì‹œ) | Multiple functions with multiple parameters in parallel (order-independent)",
            "live_simple": "ì‹¤ì œ APIë¥¼ ì‚¬ìš©í•œ ë‹¨ìˆœ í•¨ìˆ˜ í˜¸ì¶œ | Simple function calls using live/real APIs",
            "live_multiple": "ì‹¤ì œ APIì— ë‹¤ì¤‘ íŒŒë¼ë¯¸í„° í•¨ìˆ˜ | Multiple parameter functions with live APIs",
            "live_parallel": "ì‹¤ì œ API ë³‘ë ¬ í•¨ìˆ˜ í˜¸ì¶œ (ìˆœì„œ ë¬´ì‹œ) | Parallel function calls with live APIs (order-independent)",
            "live_parallel_multiple": "ì‹¤ì œ API ë³µì¡í•œ ë³‘ë ¬ í˜¸ì¶œ (ìˆœì„œ ë¬´ì‹œ) | Complex parallel calls with live APIs (order-independent)",
            "multi_turn_base": "ê¸°ë³¸ ë©€í‹°í„´ ëŒ€í™”í˜• í•¨ìˆ˜ í˜¸ì¶œ | Basic multi-turn conversational function calling",
            "multi_turn_miss_func": "í•¨ìˆ˜ ëˆ„ë½ ì²˜ë¦¬ê°€ í•„ìš”í•œ ë©€í‹°í„´ | Multi-turn with missing function handling",
            "multi_turn_miss_param": "íŒŒë¼ë¯¸í„° ëˆ„ë½ ì²˜ë¦¬ê°€ í•„ìš”í•œ ë©€í‹°í„´ | Multi-turn with missing parameter handling",
            "multi_turn_long_context": "ê¸´ ì»¨í…ìŠ¤íŠ¸ê°€ í•„ìš”í•œ ë©€í‹°í„´ | Multi-turn with extended context requirements",
            "irrelevance": "í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì§€ ë§ì•„ì•¼ í•  ë•Œ íƒì§€ | Detecting when NOT to call any function",
            "live_irrelevance": "ì‹¤ì œ APIì—ì„œ ê´€ë ¨ì—†ëŠ” í•¨ìˆ˜ í˜¸ì¶œ íšŒí”¼ | Avoiding irrelevant function calls with live APIs",
            "live_relevance": "ì‹¤ì œ APIì—ì„œ ê´€ë ¨ ìˆëŠ” í•¨ìˆ˜ íƒì§€ | Detecting relevant functions with live APIs",
            "web_search": "ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ ê¸°ëŠ¥ | Web search agent capabilities",
            "memory": "ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ | Memory management and context retention",
            "format_sensitivity": "ë‹¤ì–‘í•œ ì…ë ¥ í¬ë§·ì— ëŒ€í•œ ë¯¼ê°ë„ | Sensitivity to various input formats",
        }
        return descriptions.get(cat, "ì„¤ëª… ì—†ìŒ | No description available")

def process_test_case(handler, executor, checker, cat, q, a, max_steps=3):
    """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì²˜ë¦¬ ë¡œì§"""
    test_id = q['id']
    tools = BFCLDataLoader().get_functions(cat, q)
    gt = a['ground_truth']
    
    # ê°œì„ ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (Tool Calling Best Practices ì ìš©)
    SYSTEM_PROMPT = """You are an expert function-calling assistant. Your primary job is to call the appropriate functions with correct parameters.

CRITICAL RULES:
1. ALWAYS use the provided functions to answer user requests - this is your main purpose
2. NEVER make up or hallucinate function names - only use functions from the tools list
3. Extract parameter values directly from the user's question
4. For multi-step tasks, call functions sequentially and use their results

PARAMETER EXTRACTION:
- Read the user's question carefully to extract all required parameter values
- Use exact numbers, strings, or values provided by the user
- Follow parameter type specifications (string, number, boolean, array, object)
- If a parameter format is specified (e.g., "City, State"), follow it exactly

FUNCTION SELECTION:
- Match the user's intent to the most appropriate function name
- Check function descriptions to understand their purpose
- Consider function parameters to ensure you have the required data

MULTI-TURN BEHAVIOR:
- Use tool execution results to inform your next function call
- Chain multiple function calls when needed to complete complex tasks
- Interpret tool responses and extract relevant information for subsequent calls

Your goal is to successfully call the right functions with the right parameters."""

    # ë©€í‹°í„´ ì§ˆë¬¸ êµ¬ì¡°í™” (ìœ ì—°í•œ ëŒ€ì‘)
    raw_question = q['question']
    if isinstance(raw_question[0], list):
        user_turns = raw_question
    else:
        user_turns = [[{"role": "user", "content": msg} for msg in raw_question]]

    messages = []
    all_model_calls = []
    final_res = None
    final_content = ""

    for turn_idx, turn_msgs in enumerate(user_turns):
        messages.extend(turn_msgs)
        
        # ì—ì´ì „íŠ¸ ë£¨í”„ (ë©€í‹°í™‰ ì²˜ë¦¬)
        for step in range(max_steps):
            res = handler.inference(
                messages=[{"role": "system", "content": SYSTEM_PROMPT}] + messages,
                tools=tools,
                temperature=0,
                force_tool=(cat not in ["irrelevance", "multi_turn_miss_func"])
            )
            
            final_res = res
            final_content = res["content"]
            ast_out = handler.decode_ast(res)

            if ast_out:
                all_model_calls.extend(ast_out)
                messages.append(res["msg_obj"]) # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€
                
                # ë„êµ¬ ì‹¤í–‰ ë° ê²°ê³¼ ì¶”ê°€
                for i, call in enumerate(ast_out):
                    feedback = executor.execute(call)
                    # Tool ID ë§¤ì¹­ (OpenAI í˜¸í™˜)
                    call_id = res["msg_obj"].tool_calls[i].id if (res["msg_obj"].tool_calls and len(res["msg_obj"].tool_calls) > i) else f"call_{turn_idx}_{step}_{i}"
                    messages.append({"role": "tool", "tool_call_id": call_id, "content": feedback})
                
                # ì¹´í…Œê³ ë¦¬ë³„ ë£¨í”„ ì „ëµ
                # Simple/Single-turn ì¹´í…Œê³ ë¦¬: ì²« ë²ˆì§¸ ë„êµ¬ í˜¸ì¶œ í›„ ì¢…ë£Œ
                if cat in ["simple_python", "simple_javascript", "simple_java", "live_simple", "web_search"]:
                    break
                # Multiple/Parallel: ì—¬ëŸ¬ ë„êµ¬ë¥¼ í•œ ë²ˆì— í˜¸ì¶œ í›„ ì¢…ë£Œ (Live í¬í•¨)
                elif cat in ["multiple", "parallel", "parallel_multiple", 
                             "live_multiple", "live_parallel", "live_parallel_multiple"]:
                    break
                # Multi-turn ì¹´í…Œê³ ë¦¬: ë‹¤ìŒ ì‚¬ìš©ì í„´ìœ¼ë¡œ ì´ë™
                elif "multi_turn" in cat:
                    break
                # Relevance ì¹´í…Œê³ ë¦¬: ë‹¨ì¼ íŒë‹¨ì´ë¯€ë¡œ break
                elif cat in ["irrelevance", "live_irrelevance", "live_relevance"]:
                    break
                # Agentic ì¹´í…Œê³ ë¦¬ (memory, format_sensitivity): ë©€í‹°í™‰ ê°€ëŠ¥ì„± ìˆìŒ
                else:
                    continue
            else:
                messages.append({"role": "assistant", "content": res["content"]})
                break # ë„êµ¬ í˜¸ì¶œ ì—†ìœ¼ë©´ ë£¨í”„ ì¢…ë£Œ

    # ìµœì¢… ê²€ì¦
    is_pass, detail = checker.ast_checker(all_model_calls, gt, final_content, cat)
    
    return {
        "ì¹´í…Œê³ ë¦¬": cat, "ID": test_id, "ê²°ê³¼": "PASS" if is_pass else "FAIL",
        "ì§ˆë¬¸": str(user_turns[0][0]['content']), "ê²€ì¦ ìƒì„¸": detail,
        "ì‚¬ê³ ê³¼ì •": final_res["thinking"] if final_res else "N/A",
        "ëˆ„ì  í˜¸ì¶œ(AST)": json.dumps(all_model_calls, ensure_ascii=False),
        "ì •ë‹µ(GT)": json.dumps(gt, ensure_ascii=False),
        "Latency": final_res["latency"] if final_res else 0
    }

def run_benchmark(config):
    """
    ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        config (dict): ë²¤ì¹˜ë§ˆí¬ ì„¤ì • ë”•ì…”ë„ˆë¦¬
            - model_name: ëª¨ë¸ ì´ë¦„
            - categories: í…ŒìŠ¤íŠ¸í•  ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸
            - samples_per_cat: ì¹´í…Œê³ ë¦¬ë‹¹ ìƒ˜í”Œ ìˆ˜
            - max_agent_steps: ìµœëŒ€ ì—ì´ì „íŠ¸ ìŠ¤í…
            - rate_limit_delay: API í˜¸ì¶œ ê°„ ëŒ€ê¸° ì‹œê°„
    """
    # API í‚¤ í™•ì¸
    load_dotenv()
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        raise ValueError("OPENROUTER_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    loader = BFCLDataLoader()
    handler = ModelHandler(api_key=api_key, model_name=config["model_name"])
    checker = BFCLChecker()
    
    all_results = []
    total_samples = len(config["categories"]) * config["samples_per_cat"]
    
    print("=" * 80)
    print(f"ğŸš€ BFCL ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    print("=" * 80)
    print(f"ğŸ“‹ ëª¨ë¸: {config['model_name']}")
    print(f"ğŸ“‚ ì¹´í…Œê³ ë¦¬: {', '.join(config['categories'])}")
    print(f"ğŸ“Š ì¹´í…Œê³ ë¦¬ë‹¹ ìƒ˜í”Œ: {config['samples_per_cat']}ê°œ")
    print(f"ğŸ¯ ì´ ì˜ˆìƒ í…ŒìŠ¤íŠ¸: {total_samples}ê°œ")
    print("=" * 80)

    start_time = time.time()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    mode_tag = "QUICK" if config["samples_per_cat"] <= 2 else "FULL"
    model_short = _format_model_name_for_filename(config["model_name"])
    os.makedirs("results", exist_ok=True)
    
    for cat_idx, cat in enumerate(config["categories"], 1):
        cat_results = []
        print(f"\n[{cat_idx}/{len(config['categories'])}] ğŸ“‚ Category: {cat}")
        questions, answers = loader.load_dataset(cat, limit=config["samples_per_cat"])
        
        if not questions:
            print(f"  âš ï¸  ë°ì´í„° ì—†ìŒ, ìŠ¤í‚µ")
            continue

        for idx, (q, a) in enumerate(zip(questions, answers), 1):
            print(f"  [{idx}/{len(questions)}] Testing: {q['id'][:30]}...", end=" ")
            executor = BFCLMockExecutor(initial_config=q.get('initial_config'))
            
            try:
                result = process_test_case(
                    handler, executor, checker, cat, q, a, 
                    max_steps=config["max_agent_steps"]
                )
                all_results.append(result)
                cat_results.append(result)
                status = "âœ…" if result["ê²°ê³¼"] == "PASS" else "âŒ"
                print(f"{status} ({result['Latency']:.0f}ms)")
            except Exception as e:
                print(f"âŒ ERROR: {str(e)[:50]}")
                continue
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ ì €ì¥
        if cat_results:
            cat_df = pd.DataFrame(cat_results)
            report_path = f"results/BFCL_{mode_tag}_{model_short}_{cat}_Report_{timestamp}.xlsx"
            ExcelReporter.save(cat_df, report_path, config["model_name"], config)
            
            cat_pass = len(cat_df[cat_df['ê²°ê³¼'] == 'PASS'])
            cat_total = len(cat_df)
            cat_acc = (cat_pass / cat_total * 100) if cat_total > 0 else 0
            print(f"  ğŸ’¾ ì €ì¥ë¨: {report_path} ({cat_pass}/{cat_total}, {cat_acc:.1f}%)")
        
        # ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€ ëŒ€ê¸° (ë§ˆì§€ë§‰ ì¹´í…Œê³ ë¦¬ëŠ” ì œì™¸)
        if cat_idx < len(config["categories"]):
            print(f"  â³ {config['rate_limit_delay']}ì´ˆ ëŒ€ê¸° ì¤‘...")
            time.sleep(config["rate_limit_delay"])

    # ì „ì²´ ê²°ê³¼ í†µê³„
    if not all_results:
        print("\nâŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    
    elapsed = time.time() - start_time
    df = pd.DataFrame(all_results)
    pass_count = len(df[df['ê²°ê³¼'] == 'PASS'])
    total_count = len(df)
    accuracy = (pass_count / total_count * 100) if total_count > 0 else 0
    
    print("\n" + "=" * 80)
    print("âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
    print("=" * 80)
    print(f"ğŸ“Š ì´ í…ŒìŠ¤íŠ¸: {total_count}ê°œ")
    print(f"âœ… PASS: {pass_count}ê°œ ({accuracy:.1f}%)")
    print(f"âŒ FAIL: {total_count - pass_count}ê°œ")
    print(f"â±ï¸  ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")
    print(f"ğŸ“ ì €ì¥ í´ë”: results/ ({len(config['categories'])}ê°œ íŒŒì¼)")
    print("=" * 80)
    
    return f"results/BFCL_{mode_tag}_{model_short}_*_Report_{timestamp}.xlsx"

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="BFCL Benchmark Runner - Function Calling ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ë¹ ë¥¸ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ (3ê°œ ì¹´í…Œê³ ë¦¬ x 2ê°œ ìƒ˜í”Œ = 6ê°œ)
  python main.py --quick
  
  # ì „ì²´ ì‹¤í–‰ (ëª¨ë“  ì¹´í…Œê³ ë¦¬ x ëª¨ë“  ìƒ˜í”Œ = ~4,693ê°œ)
  python main.py --full
  
  # ì»¤ìŠ¤í…€ ì„¤ì •
  python main.py --samples 3 --categories simple_python multiple
  
  # íŠ¹ì • ëª¨ë¸ë¡œ ì‹¤í–‰
  python main.py --model "anthropic/claude-3-haiku" --samples 2
  
  # ëŒ€ê¸° ì‹œê°„ì„ ì¤„ì—¬ì„œ ë¹ ë¥´ê²Œ ì‹¤í–‰
  python main.py --quick --delay 1
        """
    )
    
    parser.add_argument(
        "--quick", 
        action="store_true",
        help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (2ê°œ ì¹´í…Œê³ ë¦¬, ê° 2ê°œ ìƒ˜í”Œ)"
    )
    
    parser.add_argument(
        "--full",
        action="store_true",
        help="ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ (ëª¨ë“  ì¹´í…Œê³ ë¦¬, ëª¨ë“  ìƒ˜í”Œ ~4,693ê°œ)"
    )
    
    parser.add_argument(
        "--samples",
        type=int,
        help="ì¹´í…Œê³ ë¦¬ë‹¹ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸ê°’: 5)"
    )
    
    parser.add_argument(
        "--categories",
        nargs="+",
        help="í…ŒìŠ¤íŠ¸í•  ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: simple_python multiple)"
    )
    
    parser.add_argument(
        "--model",
        type=str,
        help="ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: mistral-small-3.1)"
    )
    
    parser.add_argument(
        "--delay",
        type=int,
        help="ì¹´í…Œê³ ë¦¬ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’: quick=5, full=3, default=3)"
    )
    
    args = parser.parse_args()
    
    # ì„¤ì • êµ¬ì„±
    if args.quick:
        config = {**DEFAULT_CONFIG, **QUICK_TEST_CONFIG}
        print("ğŸš€ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰ (3ê°œ ì¹´í…Œê³ ë¦¬ Ã— 2ê°œ ìƒ˜í”Œ = 6ê°œ)\n")
    elif args.full:
        config = {**DEFAULT_CONFIG, **FULL_TEST_CONFIG}
        print("ğŸš€ ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ ì‹¤í–‰ (20ê°œ ì¹´í…Œê³ ë¦¬ Ã— ëª¨ë“  ìƒ˜í”Œ = ~4,693ê°œ)\n")
    else:
        config = DEFAULT_CONFIG.copy()
        
    # ì»¤ë§¨ë“œë¼ì¸ ì¸ìë¡œ ì˜¤ë²„ë¼ì´ë“œ
    if args.samples:
        config["samples_per_cat"] = args.samples
    if args.categories:
        config["categories"] = args.categories
    if args.model:
        config["model_name"] = args.model
    if args.delay is not None:
        config["rate_limit_delay"] = args.delay
    
    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    run_benchmark(config)

if __name__ == "__main__":
    main()
